{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Admission predictions Deeplearning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPfhu4FuK0aRu0Ftgy4FyLe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamednihal/Admission-prediction-deeplearning/blob/main/Admission_predictions_Deeplearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsF6qDCydAhg",
        "outputId": "26acebba-a083-4986-ee9a-76481f3fe768"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow\timport keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "# load admissions data\n",
        "admissions_data = pd.read_csv(\"admissions_data.csv\")\n",
        "print(admissions_data.head())\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
            "0           1        337          118                  4  4.5   4.5  9.65   \n",
            "1           2        324          107                  4  4.0   4.5  8.87   \n",
            "2           3        316          104                  3  3.0   3.5  8.00   \n",
            "3           4        322          110                  3  3.5   2.5  8.67   \n",
            "4           5        314          103                  2  2.0   3.0  8.21   \n",
            "\n",
            "   Research  Chance of Admit   \n",
            "0         1              0.92  \n",
            "1         1              0.76  \n",
            "2         1              0.72  \n",
            "3         1              0.80  \n",
            "4         0              0.65  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80dWCQqRiTI_",
        "outputId": "0d2682cc-94fa-4dd9-ae48-740ca19aea0f"
      },
      "source": [
        "admissions_data.describe()\n",
        "print(admissions_data.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVhwH6Ez2b1y",
        "outputId": "7fe5cb93-865f-4f3e-fdc4-31fd39ad53e3"
      },
      "source": [
        "# mark predicted values\n",
        "labels = admissions_data.iloc[:,-1]\n",
        "print(labels.describe())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    500.00000\n",
            "mean       0.72174\n",
            "std        0.14114\n",
            "min        0.34000\n",
            "25%        0.63000\n",
            "50%        0.72000\n",
            "75%        0.82000\n",
            "max        0.97000\n",
            "Name: Chance of Admit , dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "FgnXjtJt2e9j",
        "outputId": "66a2ddc6-6ad3-4ed9-d915-4e0269284aec"
      },
      "source": [
        "# mark features\n",
        "features = admissions_data.iloc[:, 1:8]\n",
        "features.describe()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.00000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>316.472000</td>\n",
              "      <td>107.192000</td>\n",
              "      <td>3.114000</td>\n",
              "      <td>3.374000</td>\n",
              "      <td>3.48400</td>\n",
              "      <td>8.576440</td>\n",
              "      <td>0.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>11.295148</td>\n",
              "      <td>6.081868</td>\n",
              "      <td>1.143512</td>\n",
              "      <td>0.991004</td>\n",
              "      <td>0.92545</td>\n",
              "      <td>0.604813</td>\n",
              "      <td>0.496884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>290.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>6.800000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>308.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>3.00000</td>\n",
              "      <td>8.127500</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>317.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.50000</td>\n",
              "      <td>8.560000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>325.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>9.040000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>340.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.00000</td>\n",
              "      <td>9.920000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        GRE Score  TOEFL Score  University Rating         SOP       LOR   \\\n",
              "count  500.000000   500.000000         500.000000  500.000000  500.00000   \n",
              "mean   316.472000   107.192000           3.114000    3.374000    3.48400   \n",
              "std     11.295148     6.081868           1.143512    0.991004    0.92545   \n",
              "min    290.000000    92.000000           1.000000    1.000000    1.00000   \n",
              "25%    308.000000   103.000000           2.000000    2.500000    3.00000   \n",
              "50%    317.000000   107.000000           3.000000    3.500000    3.50000   \n",
              "75%    325.000000   112.000000           4.000000    4.000000    4.00000   \n",
              "max    340.000000   120.000000           5.000000    5.000000    5.00000   \n",
              "\n",
              "             CGPA    Research  \n",
              "count  500.000000  500.000000  \n",
              "mean     8.576440    0.560000  \n",
              "std      0.604813    0.496884  \n",
              "min      6.800000    0.000000  \n",
              "25%      8.127500    0.000000  \n",
              "50%      8.560000    1.000000  \n",
              "75%      9.040000    1.000000  \n",
              "max      9.920000    1.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HKo3BVd2jhJ"
      },
      "source": [
        "#split our training and test set\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.25, random_state = 42)\n",
        "\n",
        "# standardizing our data by scaling it\n",
        "sc = StandardScaler()\n",
        "features_train_scale = sc.fit_transform(features_train)\n",
        "features_test_scale = sc.transform(features_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "i8pX7S602lX5",
        "outputId": "18ab5ba9-bb2a-43f7-f229-9e2513fca313"
      },
      "source": [
        "\n",
        "features_train_scale = pd.DataFrame(features_train_scale, columns = features_train.columns)\n",
        "features_test_scale = pd.DataFrame(features_test_scale, columns = features_test.columns)\n",
        "\n",
        "(features_train_scale.describe())\n",
        "(features_test_scale.describe())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>125.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>125.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.095242</td>\n",
              "      <td>-0.076851</td>\n",
              "      <td>0.034747</td>\n",
              "      <td>-0.029572</td>\n",
              "      <td>0.040541</td>\n",
              "      <td>-0.037003</td>\n",
              "      <td>0.042924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.109474</td>\n",
              "      <td>0.981014</td>\n",
              "      <td>0.972496</td>\n",
              "      <td>0.995919</td>\n",
              "      <td>1.019201</td>\n",
              "      <td>1.024542</td>\n",
              "      <td>0.998343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.435722</td>\n",
              "      <td>-2.343076</td>\n",
              "      <td>-1.827711</td>\n",
              "      <td>-2.400715</td>\n",
              "      <td>-2.687277</td>\n",
              "      <td>-2.282722</td>\n",
              "      <td>-1.116024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-1.069045</td>\n",
              "      <td>-0.705630</td>\n",
              "      <td>-0.959027</td>\n",
              "      <td>-0.888507</td>\n",
              "      <td>-0.515447</td>\n",
              "      <td>-0.768672</td>\n",
              "      <td>-1.116024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.066815</td>\n",
              "      <td>-0.214396</td>\n",
              "      <td>-0.090343</td>\n",
              "      <td>0.119633</td>\n",
              "      <td>0.027510</td>\n",
              "      <td>-0.069879</td>\n",
              "      <td>0.896038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.753191</td>\n",
              "      <td>0.604327</td>\n",
              "      <td>0.778341</td>\n",
              "      <td>0.623702</td>\n",
              "      <td>0.570467</td>\n",
              "      <td>0.778654</td>\n",
              "      <td>0.896038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.119868</td>\n",
              "      <td>2.078028</td>\n",
              "      <td>1.647025</td>\n",
              "      <td>1.631841</td>\n",
              "      <td>1.656382</td>\n",
              "      <td>2.026498</td>\n",
              "      <td>0.896038</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        GRE Score  TOEFL Score  University Rating         SOP        LOR   \\\n",
              "count  125.000000   125.000000         125.000000  125.000000  125.000000   \n",
              "mean    -0.095242    -0.076851           0.034747   -0.029572    0.040541   \n",
              "std      1.109474     0.981014           0.972496    0.995919    1.019201   \n",
              "min     -2.435722    -2.343076          -1.827711   -2.400715   -2.687277   \n",
              "25%     -1.069045    -0.705630          -0.959027   -0.888507   -0.515447   \n",
              "50%     -0.066815    -0.214396          -0.090343    0.119633    0.027510   \n",
              "75%      0.753191     0.604327           0.778341    0.623702    0.570467   \n",
              "max      2.119868     2.078028           1.647025    1.631841    1.656382   \n",
              "\n",
              "             CGPA    Research  \n",
              "count  125.000000  125.000000  \n",
              "mean    -0.037003    0.042924  \n",
              "std      1.024542    0.998343  \n",
              "min     -2.282722   -1.116024  \n",
              "25%     -0.768672   -1.116024  \n",
              "50%     -0.069879    0.896038  \n",
              "75%      0.778654    0.896038  \n",
              "max      2.026498    0.896038  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c2SV75H2lJT"
      },
      "source": [
        "# function to design the model\n",
        "def design_model(feature_data):\n",
        "\tmodel = Sequential()\n",
        "\tnum_features = feature_data.shape[1]\n",
        "\tinput = tf.keras.Input(shape=(num_features))\n",
        "\tmodel.add(input)\n",
        "\t# this model has two hidden layers and two dropout layers\n",
        "\t# relu activation function is used at both hidden layers\n",
        "\thidden_layer = layers.Dense(16, activation='relu')\n",
        "\tmodel.add(hidden_layer)\n",
        "\tmodel.add(layers.Dropout(0.1))\n",
        "\thidden_layer_2 = layers.Dense(8, activation='relu')\n",
        "\tmodel.add(hidden_layer_2)\n",
        "\tmodel.add(layers.Dropout(0.2))\n",
        "\tmodel.add(layers.Dense(1))\n",
        "\n",
        "\t# using an adam optimizer with a learning rate of 0.005\n",
        "\t# using mean-squared error as our loss function and mean average error as our metric\n",
        "\topt = keras.optimizers.Adam(learning_rate=0.005)\n",
        "\tmodel.compile(loss='mse', metrics=['mae'], optimizer=opt)\n",
        "\treturn model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQRVcgad2k8C",
        "outputId": "22b4c6de-1d6f-4d68-be50-1bdc06351365"
      },
      "source": [
        "# apply the model to the scaled training data\n",
        "model = design_model(features_train_scale)\n",
        "(model.summary())\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 16)                128       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 273\n",
            "Trainable params: 273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AryRMNXe2kud",
        "outputId": "891f81e0-4e46-40ce-8e2b-554ae892c86c"
      },
      "source": [
        "# apply early stopping for efficiency\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "\n",
        "# fit the model with 100 epochs and a batch size of 8\n",
        "# validation split at 0.25\n",
        "history = model.fit(features_train_scale, labels_train.to_numpy(), epochs=100, batch_size=8, verbose=1, validation_split=0.25, callbacks=[es])\n",
        "\n",
        "# evaluate the model\n",
        "val_mse, val_mae = model.evaluate(features_test_scale, labels_test.to_numpy(), verbose = 0)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "36/36 [==============================] - 1s 5ms/step - loss: 0.3275 - mae: 0.4543 - val_loss: 0.0512 - val_mae: 0.1886\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1074 - mae: 0.2630 - val_loss: 0.0292 - val_mae: 0.1386\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0702 - mae: 0.2069 - val_loss: 0.0228 - val_mae: 0.1264\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0513 - mae: 0.1736 - val_loss: 0.0134 - val_mae: 0.0886\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0391 - mae: 0.1501 - val_loss: 0.0160 - val_mae: 0.1110\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0311 - mae: 0.1395 - val_loss: 0.0100 - val_mae: 0.0810\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0265 - mae: 0.1264 - val_loss: 0.0093 - val_mae: 0.0785\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0186 - mae: 0.1096 - val_loss: 0.0076 - val_mae: 0.0675\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0190 - mae: 0.1106 - val_loss: 0.0070 - val_mae: 0.0629\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0163 - mae: 0.1013 - val_loss: 0.0063 - val_mae: 0.0596\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0947 - val_loss: 0.0069 - val_mae: 0.0671\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0129 - mae: 0.0892 - val_loss: 0.0057 - val_mae: 0.0581\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0941 - val_loss: 0.0053 - val_mae: 0.0528\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0769 - val_loss: 0.0059 - val_mae: 0.0603\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0814 - val_loss: 0.0058 - val_mae: 0.0588\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0772 - val_loss: 0.0055 - val_mae: 0.0572\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0771 - val_loss: 0.0052 - val_mae: 0.0517\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0757 - val_loss: 0.0050 - val_mae: 0.0519\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0788 - val_loss: 0.0052 - val_mae: 0.0471\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0077 - mae: 0.0679 - val_loss: 0.0050 - val_mae: 0.0486\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0719 - val_loss: 0.0052 - val_mae: 0.0540\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0745 - val_loss: 0.0056 - val_mae: 0.0570\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0081 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0540\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0673 - val_loss: 0.0051 - val_mae: 0.0521\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0686 - val_loss: 0.0052 - val_mae: 0.0533\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0077 - mae: 0.0669 - val_loss: 0.0059 - val_mae: 0.0613\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0089 - mae: 0.0736 - val_loss: 0.0047 - val_mae: 0.0456\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0659 - val_loss: 0.0055 - val_mae: 0.0586\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0079 - mae: 0.0667 - val_loss: 0.0051 - val_mae: 0.0545\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0078 - mae: 0.0684 - val_loss: 0.0054 - val_mae: 0.0563\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0691 - val_loss: 0.0053 - val_mae: 0.0559\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0087 - mae: 0.0719 - val_loss: 0.0055 - val_mae: 0.0579\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0081 - mae: 0.0707 - val_loss: 0.0055 - val_mae: 0.0591\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0078 - mae: 0.0686 - val_loss: 0.0078 - val_mae: 0.0752\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0089 - mae: 0.0740 - val_loss: 0.0048 - val_mae: 0.0519\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0701 - val_loss: 0.0048 - val_mae: 0.0502\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0079 - mae: 0.0692 - val_loss: 0.0045 - val_mae: 0.0462\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0703 - val_loss: 0.0047 - val_mae: 0.0468\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0072 - mae: 0.0648 - val_loss: 0.0050 - val_mae: 0.0516\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0081 - mae: 0.0694 - val_loss: 0.0056 - val_mae: 0.0605\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0692 - val_loss: 0.0048 - val_mae: 0.0510\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0659 - val_loss: 0.0052 - val_mae: 0.0574\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0072 - mae: 0.0627 - val_loss: 0.0048 - val_mae: 0.0519\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0695 - val_loss: 0.0047 - val_mae: 0.0486\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0655 - val_loss: 0.0045 - val_mae: 0.0461\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0078 - mae: 0.0688 - val_loss: 0.0048 - val_mae: 0.0498\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0671 - val_loss: 0.0051 - val_mae: 0.0545\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0083 - mae: 0.0707 - val_loss: 0.0047 - val_mae: 0.0498\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0650 - val_loss: 0.0044 - val_mae: 0.0444\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0656 - val_loss: 0.0048 - val_mae: 0.0526\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0077 - mae: 0.0677 - val_loss: 0.0051 - val_mae: 0.0569\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0643 - val_loss: 0.0044 - val_mae: 0.0457\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0636 - val_loss: 0.0047 - val_mae: 0.0532\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0668 - val_loss: 0.0060 - val_mae: 0.0646\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0663 - val_loss: 0.0046 - val_mae: 0.0507\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0081 - mae: 0.0700 - val_loss: 0.0050 - val_mae: 0.0563\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0075 - mae: 0.0677 - val_loss: 0.0050 - val_mae: 0.0525\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0642 - val_loss: 0.0050 - val_mae: 0.0500\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0636 - val_loss: 0.0068 - val_mae: 0.0688\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0075 - mae: 0.0677 - val_loss: 0.0059 - val_mae: 0.0630\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0632 - val_loss: 0.0046 - val_mae: 0.0457\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0655 - val_loss: 0.0045 - val_mae: 0.0458\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0078 - mae: 0.0670 - val_loss: 0.0048 - val_mae: 0.0522\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0601 - val_loss: 0.0046 - val_mae: 0.0469\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0630 - val_loss: 0.0061 - val_mae: 0.0638\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0675 - val_loss: 0.0057 - val_mae: 0.0544\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0075 - mae: 0.0665 - val_loss: 0.0062 - val_mae: 0.0596\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0072 - mae: 0.0655 - val_loss: 0.0051 - val_mae: 0.0511\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0083 - mae: 0.0699 - val_loss: 0.0048 - val_mae: 0.0514\n",
            "Epoch 00069: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doaRm7mi2kfG",
        "outputId": "91b20837-3d81-4da1-9881-9c0d4bee3b51"
      },
      "source": [
        "# view the MAE performance\n",
        "print(\"MAE: \", val_mae)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE:  0.05256049335002899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzp-0fVE2kQM",
        "outputId": "8e300065-c1d9-4040-c7ea-bbfc19e6da02"
      },
      "source": [
        "# evauate r-squared score\n",
        "y_pred = model.predict(features_test_scale)\n",
        "\n",
        "print(r2_score(labels_test,y_pred))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7297649682354207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "LUXrM36b3Fuy",
        "outputId": "82c5e670-ec3d-45b5-831b-d31473938fb8"
      },
      "source": [
        "# plot MAE and val_MAE over each epoch\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(2, 1, 1)\n",
        "ax1.plot(history.history['mae'])\n",
        "ax1.plot(history.history['val_mae'])\n",
        "ax1.set_title('model mae')\n",
        "ax1.set_ylabel('MAE')\n",
        "ax1.set_xlabel('epoch')\n",
        "ax1.legend(['train', 'validation'], loc='upper left')\n",
        "\n",
        "# Plot loss and val_loss over each epoch\n",
        "ax2 = fig.add_subplot(2, 1, 2)\n",
        "ax2.plot(history.history['loss'])\n",
        "ax2.plot(history.history['val_loss'])\n",
        "ax2.set_title('model loss')\n",
        "ax2.set_ylabel('loss')\n",
        "ax2.set_xlabel('epoch')\n",
        "ax2.legend(['train', 'validation'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qi4RLq93-3u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}